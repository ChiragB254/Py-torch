{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Py Torch Tutorial\n",
    "\n",
    "## Author: Chirag Bansal\n",
    "### Date: 2024-07-30\n",
    "* Description: This ipynb script demonstrates the use of PyTorch functions before diving deep into the Nural Network and CNN's using Pytorch. All these function are basic and we used them in numpy. But here I am explain how to use them in Pytorch tensors. In this file you come to know about how to initialize the tensors, `Type conversion`, `Math Functions`, `Some Comparision Functions`, `Reshaping ` and `Indexing` of Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my own tensor\n",
    "my_tensor = torch.tensor([[1,2,3,4],[5,6,7,8]],dtype=torch.float16,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other comman initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't know the values but want to initialize a tensor\n",
    "# we can use `.empty function`\n",
    "# This will create a tensor of given shape with whatever available in the memory randomly\n",
    "x = torch.empty(size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5378e-05,  8.3237e-43,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x_zero = torch.zeros((3,3))\n",
    "\n",
    "print(x_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9319, 0.5108, 0.7916],\n",
      "        [0.3704, 0.2960, 0.2342],\n",
      "        [0.0439, 0.7160, 0.3520]])\n"
     ]
    }
   ],
   "source": [
    "# create an random tensor with values in between 0 and 1\n",
    "x_rand = torch.rand((3,3))\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones((3,3))\n",
    "print(x_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# `.eye function` creates an identity matrix (one's on diagonal and zeros on the rest of places of matrix)\n",
    "x_eye = torch.eye(5,5)\n",
    "print(x_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# work same as random but we have to provide a starting and ending (not included) and the steps how many steps you want at a time\n",
    "x_arange = torch.arange(start=0,end=5,step=1)\n",
    "print(x_arange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Linespace, it will crate an tensor from starting to end including and in this `steps` means \n",
    "# how many values we need in between start and end value\n",
    "x_linespace = torch.linspace(start=0.1,end=1,steps=10)\n",
    "print(x_linespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2538, 0.2702, 0.0304]])\n",
      "tensor([[0.5387, 0.0891, 0.8837]])\n"
     ]
    }
   ],
   "source": [
    "# create an tensor with normal distribution at mean 0 and std = 1\n",
    "x = torch.empty(size=(1,3)).normal_(mean=0,std=1)\n",
    "print(x)\n",
    "\n",
    "# create an tensor with uniform distribution at mean 0 and std = 1\n",
    "x = torch.empty(size=(1,3)).uniform_(0,1)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# .diag create a diagonal matrix of one on diagonal\n",
    "x_diag = torch.diag(torch.ones(3))\n",
    "\n",
    "print(x_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to convert and initialize tensors to other types (int,float,double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "# Convert it to bool values\n",
    "print(tensor.bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "#  int 16\n",
    "print(tensor.short())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#  int 64  (Important)\n",
    "print(tensor.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "#  float 16\n",
    "print(tensor.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "#  float 32 (Important)\n",
    "print(tensor.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#  float 64\n",
    "print(tensor.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      " NP to Tensor\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "\n",
      " Tensor to NP\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Array to Tensor Conversion and vice-versa\n",
    "import numpy as np\n",
    "np_array = np.zeros((5,5))\n",
    "print(np_array)\n",
    "\n",
    "# Convert NP Array to a Tensor\n",
    "print(\"\\n NP to Tensor\")\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)\n",
    "\n",
    "# Convert Tensor to NP Array\n",
    "print(\"\\n Tensor to NP\")\n",
    "np_array_back = tensor.numpy()\n",
    "print(np_array_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Math and Comparison Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 10., 10.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([9,8,7])\n",
    "\n",
    "# Addition\n",
    "z1 = torch.empty(3)\n",
    "torch.add(x,y,out=z1)\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10])\n",
      "tensor([10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Another addition method\n",
    "z2 = torch.add(x,y)\n",
    "print(z2)\n",
    "\n",
    "# Third way\n",
    "z = x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8, -6, -4])\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "z = x-y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1111, 0.2500, 0.4286])\n"
     ]
    }
   ],
   "source": [
    "# Division\n",
    "z = torch.true_divide(x,y) # Element wise division if there are of equal shape\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'t+=x'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace operations\n",
    "\n",
    "t = torch.zeros(3)\n",
    "\n",
    "t.add_(x) # This will add x to t and store the result in t with duplicating it just mutate it \n",
    "print(t)\n",
    "\n",
    "# Another method - `t+=x` it also to inplace operation\n",
    "\n",
    "'''t+=x'''\n",
    "\n",
    "# these are more time efficent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any function with `_` in pytorch means it's an inplace operation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Exponentiation\n",
    "\n",
    "z = x.pow(2) \n",
    "print(z)\n",
    "\n",
    "# Another way to do this\n",
    "z = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True])\n",
      "tensor([False, False, False])\n"
     ]
    }
   ],
   "source": [
    "# Simple Comparision\n",
    "\n",
    "z = x > 0\n",
    "print(z)\n",
    "\n",
    "z = x<0\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) torch.Size([5, 3])\n",
      "tensor([[1.7114, 1.5789, 1.2250],\n",
      "        [1.2920, 0.9480, 0.5619]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((5,3))\n",
    "print(x1.shape, x2.shape)\n",
    "\n",
    "x3 = torch.mm(x1,x2) # 2x3\n",
    "print(x3)\n",
    "\n",
    "# Another way to do this (Easy way)\n",
    "x3 = x1.mm(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0797, 2.9595, 3.5727, 4.6210, 3.3360],\n",
      "        [3.6838, 2.0340, 2.6809, 3.0932, 2.3306],\n",
      "        [3.9513, 2.2440, 2.9045, 3.8010, 2.8852],\n",
      "        [2.7453, 1.3947, 2.1073, 2.5086, 2.1312],\n",
      "        [3.1881, 1.6408, 2.4369, 3.1864, 2.7149]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Exponentiation\n",
    "\n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(matrix_exp.matrix_power(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 16, 21])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "z = x * y\n",
    "print(z)\n",
    "# print(matrix_exp.mul(matrix_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46)\n"
     ]
    }
   ],
   "source": [
    "# dot product\n",
    "\n",
    "z = torch.dot(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.3864, 4.5019, 4.3879,  ..., 3.7000, 3.2567, 4.8732],\n",
      "         [7.2369, 6.8138, 5.9412,  ..., 6.2538, 5.5567, 6.8641],\n",
      "         [8.2836, 6.7560, 5.8781,  ..., 7.0580, 6.3247, 7.2988],\n",
      "         ...,\n",
      "         [6.1221, 4.9229, 4.7770,  ..., 6.1097, 5.1617, 6.0959],\n",
      "         [6.7976, 5.4679, 4.4277,  ..., 5.1875, 4.3848, 6.3197],\n",
      "         [6.6375, 5.5982, 4.6443,  ..., 5.5355, 5.1217, 6.1381]],\n",
      "\n",
      "        [[6.2433, 4.8275, 6.0579,  ..., 4.3919, 4.7032, 5.5916],\n",
      "         [7.2219, 5.2161, 6.8154,  ..., 6.0896, 5.5787, 7.2308],\n",
      "         [5.9265, 5.1475, 5.8021,  ..., 4.4458, 5.1117, 5.8060],\n",
      "         ...,\n",
      "         [6.4258, 4.6736, 6.0116,  ..., 4.5359, 5.0324, 5.9789],\n",
      "         [5.3812, 3.6581, 5.1210,  ..., 4.4235, 4.3529, 5.4115],\n",
      "         [5.8829, 4.1431, 5.4690,  ..., 4.9544, 4.6483, 5.8155]],\n",
      "\n",
      "        [[3.8820, 4.9864, 4.3089,  ..., 3.9572, 3.2397, 3.6117],\n",
      "         [4.0674, 5.3987, 3.9115,  ..., 4.2193, 3.3822, 3.7193],\n",
      "         [5.0277, 6.0586, 4.7439,  ..., 5.6518, 4.7461, 4.5809],\n",
      "         ...,\n",
      "         [5.3192, 5.9421, 4.5264,  ..., 4.8123, 4.0503, 4.3184],\n",
      "         [4.0807, 5.2630, 3.9703,  ..., 5.0676, 3.7778, 3.7996],\n",
      "         [5.1952, 6.6495, 4.9588,  ..., 6.3829, 5.0280, 4.8513]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.7263, 3.2325, 4.5418,  ..., 4.4130, 5.9200, 4.7138],\n",
      "         [5.0500, 4.0936, 5.0916,  ..., 5.1584, 6.0638, 5.7570],\n",
      "         [5.6369, 3.8643, 5.5024,  ..., 5.1438, 6.8332, 5.5128],\n",
      "         ...,\n",
      "         [4.9741, 3.3584, 4.7041,  ..., 4.4037, 4.5017, 5.0149],\n",
      "         [5.3912, 3.5107, 4.9012,  ..., 4.0347, 5.2217, 4.3216],\n",
      "         [5.7215, 4.1973, 5.8541,  ..., 4.5949, 6.8908, 5.8382]],\n",
      "\n",
      "        [[7.9293, 7.2149, 7.3267,  ..., 7.6831, 8.5353, 7.6768],\n",
      "         [6.1652, 5.9608, 6.6462,  ..., 6.8414, 6.6133, 5.8776],\n",
      "         [5.9165, 6.6489, 6.9318,  ..., 6.8499, 8.2031, 7.2708],\n",
      "         ...,\n",
      "         [5.0997, 4.2904, 5.1094,  ..., 5.3494, 5.7849, 4.8120],\n",
      "         [6.0686, 6.4870, 6.2689,  ..., 6.7258, 6.5425, 6.5754],\n",
      "         [7.0730, 7.0841, 7.4815,  ..., 7.4588, 7.6432, 7.0693]],\n",
      "\n",
      "        [[4.9669, 5.1650, 5.5247,  ..., 4.2022, 3.7579, 5.3338],\n",
      "         [4.5394, 4.2656, 4.6166,  ..., 3.2515, 2.8348, 4.2277],\n",
      "         [4.5502, 4.8245, 5.0373,  ..., 4.8620, 3.3415, 5.3735],\n",
      "         ...,\n",
      "         [4.5128, 5.6582, 5.5913,  ..., 5.4305, 4.1526, 5.7716],\n",
      "         [5.2224, 5.2103, 5.8596,  ..., 5.7326, 4.0132, 6.2686],\n",
      "         [5.1822, 5.0324, 5.2345,  ..., 5.4051, 4.0127, 5.8870]]])\n"
     ]
    }
   ],
   "source": [
    "# Batch Matrix Multiplication\n",
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "\n",
    "tensor1 = torch.rand((batch,n,m))\n",
    "tensor2 = torch.rand((batch,m,p))\n",
    "\n",
    "out_bmm = torch.bmm(tensor1,tensor2) # (batch,n,b)\n",
    "\n",
    "print(out_bmm)\n",
    "# print(tensor1)\n",
    "# print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5530,  0.2941, -0.0991,  0.1854,  0.2195],\n",
      "        [-0.5563, -0.0320,  0.0566,  0.2900, -0.6785],\n",
      "        [-0.6830, -0.0687,  0.2747,  0.4439, -0.1207],\n",
      "        [-0.6188,  0.0764,  0.5775,  0.8966, -0.3161],\n",
      "        [ 0.0386,  0.4428, -0.1076,  0.2749, -0.4415]])\n",
      "tensor([[0.3044, 0.8567, 0.6164, 0.8870, 0.9521],\n",
      "        [0.3007, 0.6699, 0.7305, 0.9139, 0.0922],\n",
      "        [0.1462, 0.6417, 0.8472, 0.9433, 0.6888],\n",
      "        [0.2286, 0.7423, 0.9697, 0.9991, 0.5179],\n",
      "        [0.8451, 0.9205, 0.6089, 0.9104, 0.3953]])\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# Example of Broadcasting\n",
    "\n",
    "x1 = torch.rand((5,5))\n",
    "x2 = torch.rand((1,5))\n",
    "\n",
    "z = x1 - x2\n",
    "\n",
    "print(z)\n",
    "\n",
    "z = x1**x2\n",
    "print(z)\n",
    "\n",
    "# Other useful tensor operations\n",
    "sum_x = torch.sum(x,dim=0)\n",
    "# x.sum(dim=0)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.max(x,dim = 0) # x.max(dim=0)\n",
    "print(values,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.min(x,dim = 0)  # x.min(dim=0)\n",
    "print(values,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "abs_x = torch.abs(x) # x.abs(dim=0)\n",
    "print(abs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "z = torch.argmax(x,dim = 0) # Return the index of maximum values of tensor\n",
    "# x.agemax(dim=0)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "z = torch.argmin(x,dim = 0) # Return the index of minimum values of tensor\n",
    "# x.agrmin(dim=0)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "# It take only float values, So converting the tensor into float\n",
    "mean_x = torch.mean(x.float(),dim=0)\n",
    "print(mean_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False])\n"
     ]
    }
   ],
   "source": [
    "# For Elementwise Comparision of two tensors\n",
    "\n",
    "z = torch.eq(x,y)\n",
    "# If elements are equal print true else false\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8, 9]) tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Sort\n",
    "sorted_y, indices = torch.sort(y,dim=0,descending=False)  # Specify the dimention to be sorted\n",
    "print(sorted_y,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 8, 7])\n",
      "tensor([8, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "#`torch.clamp, what it do is, for tensor x if any value is less than 0 it will clamped to (changed to 0) and if any value greater than \"specific value\" will clamped to that value (changed to specific value)`\n",
    "# `torch.clamp` is used to limit the range of a tensor or scalar.\n",
    "# It's optional to add both min and max we can use any one also\n",
    "print(y)\n",
    "z = torch.clamp(y,min = 0, max=8)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,0,1,1,1],dtype=torch.bool)\n",
    "z = torch.any(x)  # it means at least one value must be true then it will return true\n",
    "print(z)\n",
    "z = torch.all(x) # it means all values must be true only then it will retun true\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size,features))\n",
    "\n",
    "print(x[0].shape) #x[0,:]\n",
    "print(x[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6948, 0.8055, 0.2960, 0.0974, 0.3341, 0.7782, 0.0993, 0.2851, 0.3746,\n",
      "        0.3653])\n"
     ]
    }
   ],
   "source": [
    "# First 10 featuers\n",
    "print(x[2,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Fancy Indexing\n",
    "y = torch.arange(10)\n",
    "indices = [2,5,8]  # INDEX NUMBERS\n",
    "print(y)\n",
    "print(y[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6641, 0.0855, 0.8434, 0.3149, 0.8187],\n",
      "        [0.0254, 0.3695, 0.5580, 0.3728, 0.8185],\n",
      "        [0.6116, 0.6950, 0.3206, 0.8489, 0.3557]])\n",
      "tensor([0.8185, 0.6641])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand((3,5))\n",
    "print(y)\n",
    "rows = torch.tensor([1,0])\n",
    "cols = torch.tensor([4,0])\n",
    "# Element 1 = y[1,4] \n",
    "# Element 2 = y[0,0] \n",
    "print(y[rows,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advance Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 9])\n",
      "tensor([], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "\n",
    "print(x[(x<2) | (x>8)]) # it will pick out all the elements that are greater than 8 or less than 2\n",
    "print(x[(x<2) & (x>8)]) # it will pick out all the elements that are greater than 8 and less than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x[x.remainder(2)==0]) # if the remainder of x modules 2 equals to 2 then it will be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Useful operators\n",
    "print(torch.where(x>5,x,x*2)) # if x>5 then x else x*2 \n",
    "print(torch.tensor([1,1,2,3,4,4,5,6]).unique())\n",
    "print(x.ndimension()) # check how many dimensions of x we have (eg - 5x5x5 - answer will be 3)\n",
    "print(x.numel()) # check how many elements are there in x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9)\n",
    "x_3x3 = x.view(3,3)  # to make x a 3x3 matrix. it  can only operate on contiguous tensor.   \n",
    "# Contiguous array is just an array stored in an unbroken block of memory: to access the next value in the array, we just move to the next memory address.\n",
    "print(x_3x3)\n",
    "print(x_3x3.shape)\n",
    "\n",
    "# Another method\n",
    "x_3x3 = x.reshape(3,3)  # to make x a 3x3 matrix. reshape() can operate on both contiguous and non-contiguous tensor\n",
    "print(x_3x3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# to transpose it we have to make it contiguous first or we have to use `.reshape function` `.view will not work here it will give an error`\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "y = x_3x3.t()  # [0,3,6,1,4,7,2,5,8] so to transpose it for each element in original memory block we have to jump 3 time which makes it non-contiguous. So, if we want \n",
    "# to transpose it we have to make it contiguous first or we have to use `.reshape function` `.view will not work here it will give an error`\n",
    "print(y)\n",
    "\n",
    "print(y.view(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# make it contiguous first\n",
    "print(y.contiguous().view(9))\n",
    "\n",
    "# Another method use of reshape\n",
    "print(y.reshape(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "tensor([[0.6327, 0.2510, 0.9173, 0.1595, 0.7213],\n",
      "        [0.0517, 0.3009, 0.3062, 0.5540, 0.6386],\n",
      "        [0.5793, 0.9437, 0.8811, 0.0249, 0.7432],\n",
      "        [0.7536, 0.4411, 0.7437, 0.2118, 0.8691]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((2,5))\n",
    "\n",
    "print(torch.cat((x1,x2),dim=0).shape) # Concatenate along rows , dim = 0 to specify them to concat via rows for colum dim = 1\n",
    "print(torch.cat((x1,x2),dim=0)) # Concatenate along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "tensor([[0.6327, 0.2510, 0.9173, 0.1595, 0.7213, 0.5793, 0.9437, 0.8811, 0.0249,\n",
      "         0.7432],\n",
      "        [0.0517, 0.3009, 0.3062, 0.5540, 0.6386, 0.7536, 0.4411, 0.7437, 0.2118,\n",
      "         0.8691]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((x1,x2),dim=1).shape) # Concatenate along col , dim = 0 to specify them to concat via rows for colum dim = 1\n",
    "print(torch.cat((x1,x2),dim=1)) # Concatenate along col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6327, 0.2510, 0.9173, 0.1595, 0.7213, 0.0517, 0.3009, 0.3062, 0.5540,\n",
      "        0.6386])\n"
     ]
    }
   ],
   "source": [
    "z = x1.view(-1)  # To make a 1 x n dimension vector \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "x = torch.rand((batch,2,5))\n",
    "z = x.view(batch,-1) # it will make a 64 x 10 matrix\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 2])\n",
      "tensor([[[7.9770e-01, 1.7148e-01],\n",
      "         [5.9173e-01, 2.4289e-01],\n",
      "         [8.7804e-01, 7.7173e-01],\n",
      "         [8.9818e-01, 5.1646e-01],\n",
      "         [5.9191e-01, 6.6103e-01]],\n",
      "\n",
      "        [[1.6596e-01, 9.4913e-01],\n",
      "         [7.6349e-01, 8.0573e-01],\n",
      "         [5.0185e-01, 9.2574e-01],\n",
      "         [2.1424e-01, 3.4575e-02],\n",
      "         [3.7140e-01, 7.1423e-01]],\n",
      "\n",
      "        [[2.5194e-01, 3.3003e-01],\n",
      "         [2.0786e-01, 1.6912e-02],\n",
      "         [8.2335e-01, 3.0759e-01],\n",
      "         [5.3408e-01, 6.4306e-01],\n",
      "         [5.5629e-01, 3.7648e-01]],\n",
      "\n",
      "        [[3.0414e-01, 8.1636e-01],\n",
      "         [6.7368e-01, 3.2340e-01],\n",
      "         [3.3260e-02, 6.4935e-01],\n",
      "         [2.9386e-01, 3.5702e-01],\n",
      "         [1.9550e-01, 8.4384e-01]],\n",
      "\n",
      "        [[2.2406e-01, 2.0355e-01],\n",
      "         [7.7794e-01, 5.0716e-01],\n",
      "         [8.9083e-01, 7.8835e-01],\n",
      "         [4.8685e-01, 9.2288e-02],\n",
      "         [6.4902e-01, 8.8415e-01]],\n",
      "\n",
      "        [[8.7035e-01, 6.9500e-01],\n",
      "         [1.9605e-01, 7.2939e-01],\n",
      "         [1.8356e-01, 1.7348e-01],\n",
      "         [4.1342e-01, 8.4228e-01],\n",
      "         [4.8996e-01, 6.7229e-02]],\n",
      "\n",
      "        [[6.4118e-01, 6.6539e-01],\n",
      "         [1.0033e-01, 5.5604e-01],\n",
      "         [1.2750e-02, 1.6881e-02],\n",
      "         [7.3358e-01, 1.0198e-01],\n",
      "         [6.3515e-01, 2.2251e-01]],\n",
      "\n",
      "        [[5.0852e-01, 6.7077e-01],\n",
      "         [2.1067e-01, 8.3603e-01],\n",
      "         [4.6734e-01, 2.1522e-01],\n",
      "         [5.8471e-01, 8.9662e-01],\n",
      "         [2.6058e-01, 8.9586e-01]],\n",
      "\n",
      "        [[6.6306e-01, 1.5061e-01],\n",
      "         [1.7413e-01, 4.5410e-01],\n",
      "         [1.1516e-01, 4.7485e-01],\n",
      "         [7.7569e-01, 1.3849e-01],\n",
      "         [5.2371e-01, 2.6596e-01]],\n",
      "\n",
      "        [[5.0344e-01, 2.5596e-01],\n",
      "         [4.8442e-01, 5.4696e-01],\n",
      "         [2.0412e-01, 8.4958e-01],\n",
      "         [5.7193e-01, 4.7820e-01],\n",
      "         [5.7874e-01, 8.4839e-01]],\n",
      "\n",
      "        [[8.1181e-02, 2.6343e-01],\n",
      "         [1.6759e-02, 5.4120e-01],\n",
      "         [8.1539e-01, 9.1991e-01],\n",
      "         [6.7583e-01, 2.1521e-01],\n",
      "         [5.9569e-01, 9.2603e-02]],\n",
      "\n",
      "        [[6.6168e-01, 5.1617e-01],\n",
      "         [8.8921e-01, 4.4664e-01],\n",
      "         [6.8027e-01, 6.0612e-01],\n",
      "         [6.3247e-01, 7.7017e-01],\n",
      "         [5.4999e-01, 3.3555e-01]],\n",
      "\n",
      "        [[2.5359e-01, 3.5678e-03],\n",
      "         [3.7227e-02, 9.2195e-01],\n",
      "         [3.0920e-01, 6.7644e-01],\n",
      "         [9.7704e-02, 9.4720e-01],\n",
      "         [6.7794e-01, 9.3998e-01]],\n",
      "\n",
      "        [[1.6099e-01, 7.9095e-01],\n",
      "         [2.2563e-02, 3.0347e-01],\n",
      "         [9.4705e-01, 5.2699e-02],\n",
      "         [7.7647e-01, 8.5880e-02],\n",
      "         [9.1464e-01, 9.1389e-01]],\n",
      "\n",
      "        [[1.8127e-01, 5.6113e-01],\n",
      "         [7.0569e-02, 8.7099e-01],\n",
      "         [5.5456e-01, 4.8580e-01],\n",
      "         [7.6013e-01, 6.6178e-01],\n",
      "         [7.2028e-01, 6.7198e-01]],\n",
      "\n",
      "        [[4.6984e-01, 2.7180e-01],\n",
      "         [1.1384e-02, 6.9307e-01],\n",
      "         [4.7251e-01, 3.5585e-01],\n",
      "         [9.4845e-01, 4.2327e-01],\n",
      "         [1.6980e-01, 8.9899e-01]],\n",
      "\n",
      "        [[1.7599e-01, 3.1371e-01],\n",
      "         [6.1310e-01, 9.2537e-01],\n",
      "         [7.3707e-02, 5.0686e-01],\n",
      "         [5.4346e-01, 3.6659e-01],\n",
      "         [2.9494e-01, 6.3309e-01]],\n",
      "\n",
      "        [[1.4792e-01, 8.0757e-01],\n",
      "         [7.8357e-02, 2.9677e-01],\n",
      "         [2.2419e-01, 4.7725e-02],\n",
      "         [2.7641e-01, 5.3796e-01],\n",
      "         [7.3188e-01, 1.1197e-02]],\n",
      "\n",
      "        [[1.0459e-01, 5.1470e-01],\n",
      "         [2.5142e-01, 2.3673e-01],\n",
      "         [6.1506e-01, 3.9337e-01],\n",
      "         [5.6372e-01, 7.1779e-01],\n",
      "         [8.9909e-01, 7.5810e-01]],\n",
      "\n",
      "        [[6.7322e-01, 8.8791e-01],\n",
      "         [5.7503e-01, 8.4569e-01],\n",
      "         [7.2707e-01, 9.3014e-02],\n",
      "         [1.2074e-01, 5.4889e-01],\n",
      "         [1.1339e-01, 1.0838e-01]],\n",
      "\n",
      "        [[9.9203e-01, 5.0999e-02],\n",
      "         [8.2921e-01, 7.8892e-02],\n",
      "         [5.9528e-01, 4.4878e-01],\n",
      "         [6.1084e-01, 7.9247e-02],\n",
      "         [4.3471e-01, 3.6977e-01]],\n",
      "\n",
      "        [[5.9845e-01, 6.9343e-01],\n",
      "         [4.8561e-01, 3.1121e-02],\n",
      "         [9.5288e-01, 7.0305e-01],\n",
      "         [5.7200e-01, 6.2597e-01],\n",
      "         [8.5695e-02, 7.1016e-01]],\n",
      "\n",
      "        [[1.1102e-01, 6.3151e-02],\n",
      "         [2.2264e-01, 2.1440e-01],\n",
      "         [3.6357e-01, 5.6578e-01],\n",
      "         [3.8980e-01, 2.2383e-02],\n",
      "         [1.0264e-01, 7.6732e-01]],\n",
      "\n",
      "        [[1.2602e-01, 7.6412e-01],\n",
      "         [4.7874e-01, 5.9273e-01],\n",
      "         [3.1248e-01, 7.9481e-01],\n",
      "         [5.6590e-01, 5.2541e-01],\n",
      "         [3.5666e-01, 5.8416e-01]],\n",
      "\n",
      "        [[7.3945e-01, 5.3683e-01],\n",
      "         [2.0841e-01, 3.4464e-01],\n",
      "         [4.4352e-01, 1.7607e-01],\n",
      "         [4.4227e-01, 4.3563e-01],\n",
      "         [7.7778e-01, 1.6592e-01]],\n",
      "\n",
      "        [[6.4424e-01, 9.3544e-01],\n",
      "         [5.6560e-01, 8.4512e-01],\n",
      "         [8.7026e-01, 5.0794e-01],\n",
      "         [3.0998e-01, 9.0334e-01],\n",
      "         [1.0262e-01, 2.7534e-01]],\n",
      "\n",
      "        [[8.8854e-01, 8.2256e-01],\n",
      "         [7.2006e-01, 3.2132e-01],\n",
      "         [2.6483e-02, 7.3451e-02],\n",
      "         [7.7053e-01, 2.7690e-01],\n",
      "         [5.8747e-01, 9.3580e-01]],\n",
      "\n",
      "        [[8.9933e-01, 7.9900e-01],\n",
      "         [1.5685e-01, 4.7452e-01],\n",
      "         [4.6694e-01, 9.4593e-01],\n",
      "         [8.1582e-01, 2.5571e-01],\n",
      "         [5.4972e-01, 5.5403e-01]],\n",
      "\n",
      "        [[8.0267e-01, 5.2678e-01],\n",
      "         [6.2973e-01, 6.3151e-01],\n",
      "         [1.5185e-01, 3.3444e-01],\n",
      "         [7.0196e-01, 9.6758e-01],\n",
      "         [4.1698e-01, 2.5420e-01]],\n",
      "\n",
      "        [[2.5039e-01, 5.7023e-01],\n",
      "         [8.7590e-01, 1.7724e-02],\n",
      "         [1.3977e-01, 1.6764e-01],\n",
      "         [4.2066e-01, 9.9808e-01],\n",
      "         [7.3089e-01, 3.0702e-01]],\n",
      "\n",
      "        [[1.1063e-02, 4.3462e-01],\n",
      "         [5.3428e-01, 8.4157e-02],\n",
      "         [4.8192e-01, 5.2893e-02],\n",
      "         [3.6360e-02, 2.5243e-01],\n",
      "         [1.6343e-02, 1.9306e-01]],\n",
      "\n",
      "        [[9.2232e-01, 4.3217e-01],\n",
      "         [9.5241e-01, 4.8716e-01],\n",
      "         [9.4010e-01, 1.5261e-01],\n",
      "         [7.4504e-01, 4.3851e-01],\n",
      "         [8.1946e-02, 8.6179e-01]],\n",
      "\n",
      "        [[2.7794e-01, 1.7888e-01],\n",
      "         [5.1329e-01, 8.1919e-01],\n",
      "         [6.3826e-01, 8.4560e-01],\n",
      "         [5.6145e-01, 2.2252e-01],\n",
      "         [7.4369e-01, 7.4280e-01]],\n",
      "\n",
      "        [[2.6366e-01, 5.2836e-01],\n",
      "         [9.6622e-01, 5.5190e-01],\n",
      "         [4.2132e-01, 3.1125e-01],\n",
      "         [9.7705e-01, 1.5823e-01],\n",
      "         [4.9153e-01, 2.1713e-01]],\n",
      "\n",
      "        [[5.0369e-01, 6.5868e-01],\n",
      "         [7.0342e-02, 8.8871e-01],\n",
      "         [8.2547e-01, 5.7080e-01],\n",
      "         [2.6870e-01, 1.3218e-01],\n",
      "         [5.3272e-01, 2.9723e-01]],\n",
      "\n",
      "        [[4.3253e-01, 1.7501e-02],\n",
      "         [3.9121e-01, 4.0779e-01],\n",
      "         [8.4877e-01, 3.4064e-01],\n",
      "         [3.5805e-01, 1.8046e-02],\n",
      "         [3.3337e-01, 6.7815e-01]],\n",
      "\n",
      "        [[4.3882e-01, 1.8068e-01],\n",
      "         [4.0408e-01, 6.3809e-01],\n",
      "         [4.1764e-01, 6.4464e-01],\n",
      "         [7.7390e-01, 8.4628e-01],\n",
      "         [9.2774e-01, 6.1450e-01]],\n",
      "\n",
      "        [[8.2230e-01, 8.4100e-02],\n",
      "         [8.9994e-01, 7.0758e-01],\n",
      "         [4.6589e-01, 9.5461e-01],\n",
      "         [4.4903e-01, 9.8093e-01],\n",
      "         [6.7202e-01, 7.4261e-01]],\n",
      "\n",
      "        [[7.3357e-01, 2.8136e-01],\n",
      "         [5.4561e-01, 8.9670e-01],\n",
      "         [5.2470e-01, 7.2682e-01],\n",
      "         [4.6994e-01, 9.1900e-01],\n",
      "         [8.0271e-01, 2.3384e-01]],\n",
      "\n",
      "        [[6.6759e-01, 9.5587e-01],\n",
      "         [6.9878e-01, 7.5936e-01],\n",
      "         [3.4669e-01, 9.6802e-02],\n",
      "         [9.6158e-01, 1.2599e-01],\n",
      "         [9.6380e-01, 6.8861e-01]],\n",
      "\n",
      "        [[1.0650e-01, 8.0365e-01],\n",
      "         [8.8626e-01, 5.6000e-01],\n",
      "         [3.0327e-01, 4.7794e-01],\n",
      "         [1.1135e-01, 8.7969e-01],\n",
      "         [7.7665e-04, 8.1688e-01]],\n",
      "\n",
      "        [[7.3110e-02, 5.2413e-01],\n",
      "         [2.9866e-01, 4.7796e-01],\n",
      "         [2.1420e-01, 1.1280e-01],\n",
      "         [2.6887e-01, 2.0650e-01],\n",
      "         [3.8996e-01, 4.6476e-01]],\n",
      "\n",
      "        [[6.4894e-01, 1.6905e-01],\n",
      "         [3.4343e-01, 3.7988e-02],\n",
      "         [2.5116e-02, 1.4490e-01],\n",
      "         [5.2426e-01, 9.3517e-02],\n",
      "         [9.2551e-01, 8.6346e-01]],\n",
      "\n",
      "        [[9.6670e-01, 6.6883e-01],\n",
      "         [6.4566e-01, 6.9451e-01],\n",
      "         [4.2266e-01, 6.0998e-01],\n",
      "         [4.1265e-01, 8.9140e-01],\n",
      "         [5.2712e-01, 6.9583e-01]],\n",
      "\n",
      "        [[9.0107e-01, 9.5429e-01],\n",
      "         [3.9244e-01, 9.5923e-02],\n",
      "         [2.2836e-02, 7.9713e-01],\n",
      "         [1.2123e-01, 8.8540e-01],\n",
      "         [9.7068e-01, 5.6683e-01]],\n",
      "\n",
      "        [[2.6646e-01, 7.1257e-01],\n",
      "         [5.7390e-01, 5.3142e-02],\n",
      "         [6.8487e-02, 1.0862e-01],\n",
      "         [8.9134e-01, 6.0044e-02],\n",
      "         [2.8469e-01, 4.2953e-01]],\n",
      "\n",
      "        [[4.4066e-01, 5.2311e-01],\n",
      "         [6.0599e-01, 9.5654e-02],\n",
      "         [6.4290e-03, 1.3506e-01],\n",
      "         [2.7438e-01, 2.1723e-01],\n",
      "         [2.8092e-03, 8.6655e-01]],\n",
      "\n",
      "        [[1.3235e-01, 6.6432e-01],\n",
      "         [5.2105e-01, 9.7213e-01],\n",
      "         [7.3317e-01, 7.2041e-01],\n",
      "         [9.4064e-01, 2.0517e-01],\n",
      "         [7.9314e-01, 5.4836e-01]],\n",
      "\n",
      "        [[1.1380e-01, 1.0259e-01],\n",
      "         [3.3740e-01, 7.3648e-01],\n",
      "         [6.7081e-01, 3.6333e-01],\n",
      "         [4.4618e-02, 9.7049e-01],\n",
      "         [3.3969e-01, 3.3120e-01]],\n",
      "\n",
      "        [[3.3224e-01, 5.5938e-01],\n",
      "         [7.9500e-01, 5.2416e-01],\n",
      "         [3.4990e-01, 5.1362e-01],\n",
      "         [5.3515e-01, 9.0498e-01],\n",
      "         [4.8461e-02, 4.1670e-01]],\n",
      "\n",
      "        [[9.5374e-01, 5.4374e-01],\n",
      "         [6.3796e-01, 8.0640e-01],\n",
      "         [8.3043e-02, 1.8010e-02],\n",
      "         [7.1425e-01, 2.6473e-01],\n",
      "         [2.3923e-01, 5.7977e-01]],\n",
      "\n",
      "        [[4.3155e-01, 8.5325e-01],\n",
      "         [5.8600e-01, 6.4152e-01],\n",
      "         [5.1255e-01, 8.7154e-01],\n",
      "         [3.4312e-02, 8.9522e-01],\n",
      "         [6.5929e-01, 3.4125e-01]],\n",
      "\n",
      "        [[5.5777e-01, 7.0564e-01],\n",
      "         [3.4559e-01, 8.7754e-01],\n",
      "         [4.3885e-01, 1.1595e-01],\n",
      "         [6.2264e-01, 1.9625e-01],\n",
      "         [2.0726e-01, 5.3185e-01]],\n",
      "\n",
      "        [[2.6362e-01, 9.8558e-01],\n",
      "         [6.7247e-01, 5.6745e-01],\n",
      "         [1.3094e-01, 2.0855e-01],\n",
      "         [7.0176e-01, 1.8867e-01],\n",
      "         [5.1390e-01, 7.3630e-02]],\n",
      "\n",
      "        [[5.9229e-02, 4.7347e-01],\n",
      "         [1.2199e-01, 3.7322e-01],\n",
      "         [6.1855e-02, 8.1882e-01],\n",
      "         [7.7307e-01, 6.5175e-01],\n",
      "         [2.1211e-01, 4.5989e-01]],\n",
      "\n",
      "        [[5.8673e-01, 6.7335e-01],\n",
      "         [8.7194e-01, 7.5815e-01],\n",
      "         [9.7638e-01, 2.2066e-01],\n",
      "         [9.0400e-01, 8.1153e-01],\n",
      "         [7.0152e-01, 9.1651e-01]],\n",
      "\n",
      "        [[3.0570e-01, 2.7545e-01],\n",
      "         [6.9579e-01, 2.5115e-01],\n",
      "         [5.1857e-01, 8.9986e-01],\n",
      "         [8.3220e-01, 8.1238e-01],\n",
      "         [1.0902e-01, 3.8754e-01]],\n",
      "\n",
      "        [[2.6961e-01, 7.9574e-01],\n",
      "         [1.5300e-01, 5.9425e-01],\n",
      "         [9.7460e-01, 5.1271e-01],\n",
      "         [2.7450e-02, 8.7477e-01],\n",
      "         [2.8855e-01, 6.3244e-01]],\n",
      "\n",
      "        [[8.8141e-01, 2.3813e-02],\n",
      "         [1.0797e-01, 9.4033e-01],\n",
      "         [4.3779e-01, 4.8017e-01],\n",
      "         [6.6783e-01, 3.2330e-02],\n",
      "         [4.4968e-01, 6.7400e-01]],\n",
      "\n",
      "        [[5.8325e-01, 7.4171e-01],\n",
      "         [9.8219e-01, 6.0359e-01],\n",
      "         [2.4812e-01, 3.4413e-02],\n",
      "         [5.8184e-01, 9.0938e-02],\n",
      "         [1.5155e-01, 8.9774e-01]],\n",
      "\n",
      "        [[1.8180e-01, 1.0368e-01],\n",
      "         [8.7336e-01, 2.0694e-01],\n",
      "         [7.6146e-01, 1.2949e-01],\n",
      "         [4.5651e-01, 9.7291e-02],\n",
      "         [7.4040e-01, 1.4076e-01]],\n",
      "\n",
      "        [[6.0242e-01, 2.6701e-01],\n",
      "         [5.0607e-01, 5.3974e-01],\n",
      "         [2.8742e-01, 3.2257e-01],\n",
      "         [6.7463e-01, 7.8983e-02],\n",
      "         [2.8365e-01, 5.6424e-01]],\n",
      "\n",
      "        [[6.2841e-01, 6.2365e-01],\n",
      "         [5.3413e-01, 5.9573e-01],\n",
      "         [5.9418e-01, 3.9068e-01],\n",
      "         [4.3536e-01, 7.1374e-01],\n",
      "         [1.4813e-01, 4.1373e-01]],\n",
      "\n",
      "        [[9.8518e-01, 4.8531e-01],\n",
      "         [8.1706e-01, 8.7385e-02],\n",
      "         [7.5240e-01, 9.1778e-01],\n",
      "         [1.2349e-01, 9.2812e-01],\n",
      "         [4.9602e-01, 7.4794e-01]]])\n"
     ]
    }
   ],
   "source": [
    "z = x.permute(0,2,1) # .permute is use to change the dimensions in this case we want 0 at 0 , 2 at 1 and 1 at 2\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "\n",
      "\n",
      "torch.Size([10, 1])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10) # [10]\n",
    "print(x.unsqueeze(0).shape) # it will add a dimension at 0 index [1,10]\n",
    "print(x.unsqueeze(0))\n",
    "print(\"\\n\")\n",
    "print(x.unsqueeze(1).shape) # it will add a dimension at 1 index [10,1]\n",
    "print(x.unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
      "torch.Size([1, 1, 10])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1) # 1X1X10\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "z = x.squeeze(1) # it will remove the dimension at 1 index\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
